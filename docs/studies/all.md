ğŸ”¥ 1. Uber â€“ Rewriting the Marketplace Matching Engine

Problem: High tail latencies in trip-matching; Python services couldnâ€™t keep up under surge.
Cause: Too much GC pressure, slow serialization, too many cross-service hops.
Solution:

Rewrote core matching in Go for tighter latency bounds

Built a custom RPC layer using protobufs and zero-copy encoding

Introduced event-driven architecture with Kafka for predictable scaling

Locality-aware scheduling to reduce cross-zone traffic

Impact: Latencies dropped from hundreds of ms â†’ tens of ms.

ğŸ”¥ 2. Cloudflare â€“ Replacing Python with Rust in Their DNS Path

Problem: Hot paths in DNS resolver were CPU-bound; Python couldn't hit needed QPS.
Bottleneck: Per-request memory allocation + GIL.
Solution:

Rewrote hot components in Rust, kept Python for orchestration

Used lock-free data structures for shared cache

Leveraged zero-copy buffers for packet parsing

Impact: 10Ã— throughput increase without increasing hardware.

ğŸ”¥ 3. Discord â€“ Scaling to Millions of WebSocket Connections

Problem: Gateway cluster hitting CPU and connection limits.
Cause: Erlang node couldnâ€™t efficiently multiplex millions of WS clients.
Solution:

Migrated gateway to Rust using Tokio

Implemented sharded architecture for each guild (server)

Disabled Nagle and optimized TCP settings

Built a batched event dispatcher to reduce fan-out cost

Impact: Handled millions of concurrent connections per machine.

ğŸ”¥ 4. Netflix â€“ Solving Java GC Pauses in High-Traffic Streams

Problem: Kafka consumer services had unpredictable GC pauses â†’ video stutters.
Cause: Large heap + allocation-heavy deserialization code.
Solution:

Moved to off-heap buffers with Netty

Switched from Jackson to protobuf with pre-allocated objects

Tuned GC to use G1 with small regions

Added circuit breakers for backpressure

Impact: GC pauses dropped by ~90%.

ğŸ”¥ 5. Pinterest â€“ Fixing HBase Tail Latency

Problem: Recommendation system queries spiked to multi-second latency.
Cause: HBase compactions + hotspotting.
Solution:

Redesigned data layout using hash-distributed keys

Offloaded heavy aggregations to Spark streaming

Added auto-tiering between SSD and HDD

Impact: p99 latency stabilized under 50 ms.

ğŸ”¥ 6. Figma â€“ Rewriting Multiplayer Engine With Custom CRDT

Problem: Real-time collaboration was hitting bandwidth + CPU limits.
Cause: Their OT-based system required too many transformations.
Solution:

Built a custom CRDT optimized for graphics objects

Implemented binary deltas instead of JSON

Used sharded document state to isolate hot areas

Impact: Real-time sync became smooth even with huge documents.

ğŸ”¥ 7. LinkedIn â€“ Solving Feed Ranking Latency

Problem: Feed ranking SLA missed due to scatter-gather across too many backends.
Cause: Large fan-out requests â†’ tail latency explosion.
Solution:

Built Voldemort â€œread repairâ€ cachesâ€ near compute nodes

Switched to micro-batching of ranking requests

Introduced predictive caching for user segments

Impact: 40% reduction in datacenter traffic, big latency win.

ğŸ”¥ 8. Shopify â€“ Handling Black Friday Traffic Spikes

Problem: Checkout service overloaded when traffic spiked 20Ã—.
Cause: Centralized Rails monolith couldnâ€™t horizontally scale.
Solution:

Broke out the checkout pipeline into Go microservices

Added Kafka-driven async workflows

Used read replicas with aggressive caching

Introduced rate-limiting per merchant

Impact: Stable at 99.999% uptime during BF.

ğŸ”¥ 9. Instagram â€“ Migrating Async Jobs to Celery â†’ Custom Go Workers

Problem: Media processing jobs lagged behind; Celery couldnâ€™t handle burst traffic.
Cause: Python workers â†’ high CPU load + slow scheduling.
Solution:

Built Go-based job workers with priority queues

Used S3 multipart uploads + parallelism

Implemented idempotent jobs for retry correctness

Impact: Latency dropped massively; backlog disappeared.

ğŸ”¥ 10. Twitch â€“ Scaling Chat to Millions

Problem: IRC-based chat backend choking on massive fan-out.
Cause: Too many channels + too many messages per second.
Solution:

Built multi-layered fan-out architecture

Used Golang for chat servers

Implemented sharding by channel ID

Wrote a custom TCP load-balancer tuned for short messages

Impact: Sustains millions of msgs/sec globally.
